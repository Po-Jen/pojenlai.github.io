<!DOCTYPE html>
<html class="t-white">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>scikit-learn Sparse Utils Now Support Fused Types</title>
  <meta name="description" content="Dealing with sparse data is fairly common when we are anlyzing large datasets. However, sparse function utilities in scikit-learn only support float64 curren...">

  <link href='https://fonts.googleapis.com/css?family=Roboto:400,400italic,700|Roboto+Mono:400,500' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://yclin.me/2016/05/sparse-func-utils">
  <link rel="alternate" type="application/rss+xml" title="Yen" href="http://yclin.me/feed.xml">
</head>

  <body>
    <nav class="c-navigation is-fixed">
  <div class="c-navigation__container u-container">
    <a class="c-navigation__item " href="/">About</a>
    <a class="c-navigation__item " href="/blog/">Blog</a>
    <!-- <a class="c-navigation__item " href="/about/">About</a> -->
  </div>
</nav>


    <article class="c-article">
  <header class="c-header c-article__header">
    <div class="u-container">
      <h1 class="c-header__title">scikit-learn Sparse Utils Now Support Fused Types</h1>
    </div>
  </header>

  <div class="c-article__main">
    <p>Dealing with sparse data is fairly common when we are anlyzing large datasets. However, sparse function utilities in scikit-learn only support <code class="highlighter-rouge">float64</code> currently and will therefore implicitly convert other input data types, e.g., <code class="highlighter-rouge">float32</code>, into <code class="highlighter-rouge">float64</code>, which may cause unexpected memory error. Since <a href="http://docs.cython.org/src/userguide/fusedtypes.html">Cython fused types</a> allow us to have one type definition that can refer to multiple types, we can solve potential memory wasting issue by substituting <code class="highlighter-rouge">float64</code> with Cython fused types.</p>

<p>Below, I’ll briefly introduce sparse function utilities in scikit-learn and describe the work I’ve done to enhance it during GSoC.</p>

<h2 id="sparse-function-utilities">Sparse Function Utilities</h2>

<p>In scikit-learn, sparse data is often represented as <code class="highlighter-rouge">scipy.sparse.csr_matrix</code> or <code class="highlighter-rouge">scipy.sparse.csc_matrix</code>. However, these two matrices do not provide built-in methods to calculate important statistics such as <em>L2 norm</em> and <em>variance</em>, which are useful when we are playing with data. Therefore, scikit-learn leverages on <code class="highlighter-rouge">sparsefuncs_fast.pyx</code> which defines some helper methods for sparse matrices to handle sparse data more conveniently throughout the project.</p>

<h2 id="memory-wasting-issue">Memory Wasting Issue</h2>

<p>However, original implementation of sparse function utilities in scikit-learn is not memory-efficient.</p>

<p>Let’s take a simple function which do not use Cython fused types and will calculate <em>L2 norm</em> of a CSR matrix <code class="highlighter-rouge">X</code> as example:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">csr_row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="s">"""L2 norm of each row in CSR matrix X."""</span>
    
    <span class="c"># 1</span>
    <span class="n">cdef</span><span class="p">:</span>
        <span class="n">unsigned</span> <span class="nb">int</span> <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">unsigned</span> <span class="nb">int</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64_t</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">norms</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64_t</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">data</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">indices</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">indptr</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">indptr</span>

        <span class="n">np</span><span class="o">.</span><span class="n">npy_intp</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span>
        <span class="n">double</span> <span class="n">sum_</span>
	 
	 <span class="c"># 2</span>
    <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    
    <span class="c"># 3</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="c"># Warning: might copy!</span>

    <span class="c"># 4</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">sum_</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">indptr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">indptr</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]):</span>
            <span class="n">sum_</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">data</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">norms</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_</span>
	 
	 <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span>
	 
    <span class="k">return</span> <span class="n">norms</span>
</code></pre>
</div>

<ol>
  <li>
    <p>Declare Cython’s <strong>static-typed</strong> (in contrast to Python’s <strong>dynamic-typed</strong>) variables to store attributes of the input CSR matrix X since static-typed variables can accelerate the computation a lot.</p>
  </li>
  <li>
    <p>Initialize <code class="highlighter-rouge">norms</code> with 0s.</p>
  </li>
  <li>
    <p>Since we’ve already used <code class="highlighter-rouge">cdef</code> to declare <code class="highlighter-rouge">data</code> as a <code class="highlighter-rouge">np.ndarray</code> which contains <code class="highlighter-rouge">np.float64_t</code> element in step 1, data of X need to be converted into type <code class="highlighter-rouge">np.float64</code> if it belongs to other data types.</p>
  </li>
  <li>
    <p>Calculate the squared sum of each row and then take squared root of it to get <em>L2 norm</em>.</p>
  </li>
</ol>

<p>As illustrated above, we can see that <strong>STEP 3 IS DANGEROUS</strong> because converting type of data may implicitly copy the the data and then <a href="https://github.com/scikit-learn/scikit-learn/issues/5776">cause memory error</a> unexpectedly. To see how it will affect the memory space, we can use <a href="https://github.com/fabianp/memory_profiler">memory_profiler</a> to monitor memory usage.</p>

<p>Here is the result of memory profiling if we pass a <code class="highlighter-rouge">scipy.sparse.csr_matrix</code> with <code class="highlighter-rouge">np.float32</code> element into our example function:</p>

<p><img src="../../assets/2016-05-29/no_fused_types.png" alt="" /></p>

<p>It is abvious that memory usage increase dramatically because step 3 copies the data so as to convert it from <code class="highlighter-rouge">np.float32</code> to <code class="highlighter-rouge">np.float64</code>.</p>

<p>To solve this problem, we can introduce Cython fused types to avoid data copying. But firstly, let’s take a brief look at Cython fused types.</p>

<h2 id="cython-fused-types">Cython Fused Types</h2>

<p>Here is <a href="http://docs.cython.org/src/userguide/fusedtypes.html">official page</a>’s clear introduction for fused types:</p>

<blockquote>
  <p>Fused types allow you to have one type definition that can refer to multiple types. This allows you to write a single static-typed cython algorithm that can operate on values of multiple types. Thus fused types allow generic programming and are akin to templates in C++ or generics in languages like Java / C#.</p>
</blockquote>

<p>Note that Cython fused types are specialized at <strong>compile time</strong>, and are <strong>constant</strong> for a particular function invocation.</p>

<p>By adopting Cython fused types, our function can accept multiple types and therefore doesn’t need to do datatype conversion.</p>

<h2 id="common-pitfalls">Common Pitfalls</h2>

<p>Intuitively, in order to integrate Cython fused types to solve the memory issue described above, we will delete step 3 and change step 1 in our function as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    <span class="c"># 1</span>
    <span class="n">cdef</span><span class="p">:</span>
        <span class="n">unsigned</span> <span class="nb">int</span> <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">unsigned</span> <span class="nb">int</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c"># Change type from np.float64_t to floating</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">floating</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">norms</span> 
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">floating</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span> 
        
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">indices</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">indptr</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">indptr</span>

        <span class="n">np</span><span class="o">.</span><span class="n">npy_intp</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span>
        <span class="n">double</span> <span class="n">sum_</span>

</code></pre>
</div>

<p>However, above changes will cause Cython compile error <code class="highlighter-rouge">Invalid use of fused types, type cannot be specialized</code>.</p>

<p>It seems that Cython doesn’t allow us to declare fused types variable and then assign value to it within a function <strong>if this function doesn’t accept any argument that has type involves the same fused types</strong>. Hence, we need to introduce a implementation trick here.</p>

<h2 id="enhanced-implementation">Enhanced Implementation</h2>

<p>The trick I used here is to define a wrapper function and make its underlying implementation function accept fused types arguments. The reason behind this is mentioned above:</p>

<p><strong>If a function accepts some argument that has a particular fused type</strong>, it can use <code class="highlighter-rouge">cdef</code> to declare and init variable with that particular fused type within its scope.</p>

<p>Code of enhanced implementation is showed below:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># Wrapper function</span>
<span class="k">def</span> <span class="nf">csr_row_norms</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="s">"""L2 norm of each row in CSR matrix X."""</span>
    <span class="k">return</span> <span class="n">_csr_row_norms</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">indptr</span><span class="p">)</span>

<span class="c"># Underlying implementation function</span>
<span class="k">def</span> <span class="nf">_csr_row_norms</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">floating</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">X_data</span><span class="p">,</span>
                   <span class="n">shape</span><span class="p">,</span>
                   <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">X_indices</span><span class="p">,</span>
                   <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">X_indptr</span><span class="p">):</span>
    <span class="n">cdef</span><span class="p">:</span>
        <span class="n">unsigned</span> <span class="nb">int</span> <span class="n">n_samples</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">unsigned</span> <span class="nb">int</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">DOUBLE</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"c"</span><span class="p">]</span> <span class="n">norms</span>

        <span class="n">np</span><span class="o">.</span><span class="n">npy_intp</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span>
        <span class="n">double</span> <span class="n">sum_</span>

    <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">sum_</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_indptr</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">X_indptr</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]):</span>
            <span class="n">sum_</span> <span class="o">+=</span> <span class="n">X_data</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_data</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">norms</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_</span>

    <span class="k">return</span> <span class="n">norms</span>
</code></pre>
</div>

<p>Finally, to verify our enhancement, here is the result of memory profiling if we pass a <code class="highlighter-rouge">scipy.sparse.csr_matrix</code> with <code class="highlighter-rouge">np.float32</code> element into our enhamced function:</p>

<p><img src="../../assets/2016-05-29/fused_types.png" alt="" /></p>

<p>Cool! As what figure shows, our function no longer copy the data anymore.</p>

<h2 id="summary">Summary</h2>

<p>All of the functions in <code class="highlighter-rouge">sparsefuncs_fast.pyx</code> now support Cython fused types! Great thanks to all of the reviewers and their useful opinions.</p>

<p>In the next few weeks, my goal is to work on clustering algorithms such as KMeans in scikit-learn so as to make it also support Cython fused types.</p>


<div id="disqus_thread"></div>
<script>
/**
* RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
* LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
*/

var disqus_config = function () {
this.page.url = PAGE_URL; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');

s.src = '//yclin-blog.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


  </div>
</article>


    <footer class="c-footer">
  <div class="u-container c-footer__container">
    <p>&copy; Yen 2016</p>
    <p>
      <a href="https://twitter.com/yenchenlin1994">Twitter</a>
      <a href="https://github.com/yenchenlin1994">Github</a>
      
      
    </p>
  </div>
</footer>

  </body>
</html>
